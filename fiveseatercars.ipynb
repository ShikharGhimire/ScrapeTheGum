{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "- Let's extract the data first and concat the two json file into single csv file. Save the csv file\n",
    "- Data exploration afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json('gumtree.json')\n",
    "# df2 = pd.read_json('remaininggumtree.json')\n",
    "# data = pd.concat([df,df2])\n",
    "# #Saving it as a final_data.csv\n",
    "# data.to_csv('final_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('finals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Body type', 'Mileage', 'Transmission',\n",
       "       'Brochure Engine size', 'Fuel type', 'Urban mpg', 'Extra Urban mpg',\n",
       "       'Fuel Consumption', 'Insurance Group', 'CO2 emissions',\n",
       "       'Euro Emissions', 'Engine Power', 'Engine size',\n",
       "       'Acceleration (0-62mph)', 'Top Speed', 'Seats', 'Doors', 'Colour',\n",
       "       'Fuel Capacity', 'Luggage Capacity (seats up)', 'Price', 'Name',\n",
       "       'Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check out the coloumn names\n",
    "dataset.columns #All the coloumns here are important so we won't be deleting it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#However some of the coloumns needs some renaming to be done \n",
    "#The reason we are doing this is because we want\n",
    "dataset.rename({'Acceleration (0-62mph)':'Acceleration(0-62mph)','Luggage Capacity (seats up)':'Luggage Capacity(seats_up)'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if there is any duplicate values in the dataset\n",
    "#Let's find out duplicate values\n",
    "dataset.duplicated().sum() #There are alltogether 300 values that are duplicate\n",
    "#Let's see what those duplicate values are\n",
    "duplicates = dataset[dataset.duplicated()]\n",
    "#duplicates.to_csv('duplicates.csv',index=False) #Exporting to csv to further analyse the data properly.(Not necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remove the duplciates from the main dataset\n",
    "final_dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's work with the dataset now that the duplicates has been removed. \n",
    "#We see alot of blank data so let's replace the blank data points with NaN\n",
    "final_dataset = final_dataset.replace(r'^\\s*$',np.nan,regex = True) #Using regex\n",
    "\n",
    "#Let's also remove unwanted spaces from the string coloumn name\n",
    "final_dataset['Name'] = final_dataset['Name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_dataset.to_csv('finals.csv',index=False) #We sucessfully removed all the 300 duplicates from the data. \n",
    "#Before the data dimanesion was 1078 rows Ã— 24 columns and now after removing 300 duplicate values, it is 778 rows Ã— 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remove the unwanted columns\n",
    "final_dataset.drop(['Urban mpg','Extra Urban mpg'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's clean coloumns that needs cleaning\n",
    "def remove_html_tags(string):\n",
    "    result = re.sub('</h1','',string)\n",
    "    return result\n",
    "\n",
    "def remove_emojis(col): #Upon careful looking at the dataset carefully, there is an emoji 'ðŸ’¥' that is in dataset s\n",
    "    col = col.apply(lambda x: x.encode('ascii','ignore').decode('ascii')) #let's remove it. \n",
    "    return col\n",
    "\n",
    "final_dataset['Name'] = final_dataset['Name'].apply(lambda x : remove_html_tags(x))\n",
    "final_dataset['Name'] = remove_emojis(final_dataset['Name']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's seperate the dataset by creating a different variable for only the empty borchure size\n",
    "empty_brochure = final_dataset[final_dataset['Brochure Engine size'].isna()] \n",
    "\n",
    "#Let's remove the nan file with the one we googled.\n",
    "empty_brochure['Brochure Engine size'][empty_brochure.Name=='Toyota Hilux 3.0l Invincible'] = '3.0L' #For the Toyota\n",
    "empty_brochure['Brochure Engine size'][empty_brochure.Name=='2011 Volkswagen Golf Match TDI 1.6 105 PS Hatchback Diesel Manual'] = '1.6L' #For volkswagen hatchback\n",
    "empty_brochure['Brochure Engine size'][empty_brochure.Name=='2021 Citroen C4 50kWh Shine Plus Auto 5dr Hatchback Electric Automatic'] = 'Electric engine' #For Citroen C4\n",
    "empty_brochure['Brochure Engine size'][empty_brochure.Name=='2021 Nissan Navara Brand new 2121 model  Double Cab Pick Up N-Guard in stock  wi'] = '2.3L' #For volkswagen hatchback\n",
    "\n",
    "#Merge the final dataset with updated empty brochure updated data\n",
    "final_dataset.update(empty_brochure) #It has been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's work on fuel consumption empty data and turning it into dictionary\n",
    "fuel_consumption = final_dataset[final_dataset['Fuel Consumption'].isna()] \n",
    "\n",
    "name = list(fuel_consumption['Name'])\n",
    "consumption = ['62.8mpg','0mpg','0mpg','0mpg','0mpg','60mpg','0.0mpg','65.7mpg'] #Co\n",
    "consumption_dict = dict(zip(name,consumption))\n",
    "\n",
    "for i,j in consumption_dict.items():\n",
    "    fuel_consumption['Fuel Consumption'][fuel_consumption.Name=='{}'.format(i)] = '{}'.format(j)\n",
    "\n",
    "final_dataset.update(fuel_consumption) #Updating the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there is only one missing value for CO2 emissions, let's use the normal way to fill in the data\n",
    "CO2_emission = final_dataset[final_dataset['CO2 emissions'].isna()] \n",
    "\n",
    "#CO2 emission filling\n",
    "CO2_emission['CO2 emissions'][CO2_emission.Name=='2011 Volkswagen Golf Match TDI 1.6 105 PS Hatchback Diesel Manual'] = '119g/km'\n",
    "\n",
    "final_dataset.update(CO2_emission) #Updating the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's work on the missing Euro Emissions\n",
    "euro_emission = final_dataset[final_dataset['Euro Emissions'].isna()] \n",
    "car_name = list(euro_emission['Name'])\n",
    "euro_missing = ['Euro 3','Euro 5','Euro 3','Euro 2']\n",
    "\n",
    "#Converting it into dictionary\n",
    "euro_dict = dict(zip(car_name,euro_missing))\n",
    "\n",
    "#Filling the data\n",
    "for i,j in euro_dict.items():\n",
    "    euro_emission['Euro Emissions'][euro_emission.Name=='{}'.format(i)] = '{}'.format(j)\n",
    "    \n",
    "final_dataset.update(euro_emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_power = final_dataset[final_dataset['Engine Power'].isna()] \n",
    "engine_power['Engine Power'][engine_power.Name=='2011 Volkswagen Golf Match TDI 1.6 105 PS Hatchback Diesel Manual'] = '103.3bhp'\n",
    "final_dataset.update(engine_power) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speed = final_dataset[final_dataset['Top Speed'].isna()] \n",
    "top_speed['Top Speed'][top_speed.Name=='2011 Volkswagen Golf Match TDI 1.6 105 PS Hatchback Diesel Manual'] = '117mph'\n",
    "final_dataset.update(top_speed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For seats\n",
    "seats = final_dataset[final_dataset['Seats'].isna()] \n",
    "seats['Seats'][seats.Name=='2011 Volkswagen Golf Match TDI 1.6 105 PS Hatchback Diesel Manual'] = '5'\n",
    "final_dataset.update(seats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For doors\n",
    "doors = final_dataset[final_dataset['Doors'].isna()] \n",
    "doorcar_name = list(doors['Name'])\n",
    "doors_missing = ['5','5','5']\n",
    "seat_dict = dict(zip(doorcar_name,doors_missing))\n",
    "\n",
    "for i,j in seat_dict.items():\n",
    "    doors['Doors'][doors.Name=='{}'.format(i)] = '{}'.format(j)\n",
    "    \n",
    "final_dataset.update(doors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's work for the acceleration\n",
    "acceleration = final_dataset[final_dataset['Acceleration (0-62mph)'].isna()]\n",
    "acceleration_name = list(acceleration['Name'])\n",
    "acceleration_missing = ['11.0seconds','7.5seconds','5.9seconds','9.3seconds','5.5seconds','9.2seconds','7.5seconds','11.8seconds','9.7seconds','17.3seconds','7seconds','12seconds','10.7seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration_dict = dict(zip(acceleration_name,acceleration_missing))\n",
    "for i,j in acceleration_dict.items():\n",
    "    acceleration['Acceleration (0-62mph)'][acceleration.Name=='{}'.format(i)] = '{}'.format(j)\n",
    "    \n",
    "final_dataset.update(acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like there are alot of missing values that we need to handle. The coloumns with missing values are\n",
    "#Brochure Engine Size\n",
    "#Urban mpg\n",
    "#Extra Urban mpg\n",
    "#Insurance group\n",
    "#C02 emissions\n",
    "#Euro Emissions\n",
    "#Engine Power\n",
    "#Acceleration\n",
    "#Top Speed\n",
    "#Seats\n",
    "#Doors\n",
    "#Fuel Capacity\n",
    "#Luggage Capacity\n",
    "#Let's work on the missing values one by one. The good thing about missing values in car is that you can simply manually google it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brochure engine size\n",
    "#Before googling the data, we need to check which rows of brochure engine size datas are missing from and which car it belongs to\n",
    "# The four missing values for borchure are \n",
    "#2008 Toyota Hilux 3.0l Invincible ---> 3.0L\n",
    "#2011 Volkswagen golf match TDI 1.6 105 PS HatchBack -->1.6L\n",
    "#2021 Citroen C4 50kWh Shine Plus Auto 5dr HatchBack --Electric\n",
    "#2021 Nissan Navara Brand new 2121 model Double hatchback-->2.3L\n",
    "\n",
    "#Looks like some of the empty brochure size is of that of electric cars, so let's clean that aswell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
